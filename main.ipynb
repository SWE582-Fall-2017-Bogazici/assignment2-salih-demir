{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best w (numpy result): [ 3.00009091  0.50009091]\n",
      "min error (numpy result): 1.25115363636 \n",
      "\n",
      "error: 15.993881818181819 | alpha: 0.001000000000000 | learning rate: 1.100000000000000\n",
      "error: 11.112501245887605 | alpha: 0.001000000000000 | learning rate: 1.100000000000000\n",
      "error: 4.904173700057307 | alpha: 0.001000000000000 | learning rate: 1.100000000000000\n",
      "error: 1.495780331088420 | alpha: 0.001000000000000 | learning rate: 1.100000000000000\n",
      "error: 1.375828233608209 | alpha: 0.000825201702859 | learning rate: 1.000781250000000\n",
      "error: 1.369296137839704 | alpha: 0.000823913667101 | learning rate: 1.000000000000001\n",
      "error: 1.368551141532561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.361282665670135 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.349315554048530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.336920939557256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.328411416603352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.322108812303618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.317073859628759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.312789194829180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.308974733832064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.305481417521842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.305008277385969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.302230920098890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.300913953985659 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.299182022722564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.297416432555386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.296312258744376 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.294338576308774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.293608170008988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.293031400525009 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.291569871784540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.291060325777020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.290065997148115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.289040572050780 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.288660911465683 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.288403274328034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.287445872388685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.286705811894264 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.286402658944733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.285799781801352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.285088249544358 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.284535891520374 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.284278445061689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.284272905904685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.283977093819323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.283481444376108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282938184657428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282510360361141 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282281199552687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282214619044793 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282187305376598 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282067182227481 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.281789202414809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.281385704758815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280958534737535 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280614431582354 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280403938398555 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280298167166623 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280212916210556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280061833839368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.279805619753198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.279469723143039 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.279123563350293 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278836819220957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278639833645980 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278510206915616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278390635231692 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278224822577239 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.277989319725419 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.277703615235300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.277414871061978 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.277168439170768 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276982280632862 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276839426738401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276701002178650 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276530413350736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276313883574856 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276066035329596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275818808855925 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275601631760472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275424948618069 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275276131768046 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275128887208658 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274959500898147 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274760036901451 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274541293128416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274324835572125 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274129697351422 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273961812523122 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273811915517902 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273662273099497 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273497566520978 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273313342374042 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273117472365320 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272924475053990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272746618556831 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272587168288298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272439403257505 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272291396844078 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272133286380525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271962662568660 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271785202938963 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271610653493921 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271446892953320 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271295635753664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271152053051434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271008144843979 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270857583410990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270699135419428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270536858837912 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270377277342014 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270225430745583 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270082152868220 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269944002278203 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269805626563815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269662980870554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269515490527676 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269366033178240 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269218963151916 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269077490350909 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268941964359748 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268809949478845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268677873474695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268543160755717 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268405591922389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268267193420364 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268130863244138 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267998635992974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267870607217220 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267745063327562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267619625785258 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267492661222559 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267364131161384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267235453656966 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267108551735424 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266984708030773 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266863894638546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266744912235038 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266626180591915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266506668267911 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266386420202008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266266422943131 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266147948593311 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266031800675177 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265917899540670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265805409542259 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265693282960063 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265580871310464 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265468250479202 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265356103030706 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265245267671048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265136244047064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265028938318107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264922770441292 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264817047006105 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264711362101094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264605795941890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264500818234529 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264396979914115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264294588864832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264193555248154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264093477695709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263993897957876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263894563041452 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263795545313106 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263697166244294 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263599786225570 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263503592812248 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263408507748485 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263314253962849 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263220528910254 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263127175500081 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263034253824477 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262941982644615 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262850596546343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262760208067444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262670752569809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262582039079874 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262493867907439 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262406141769759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262318907978407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262232314464213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262146513001640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262061569711448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261977432931635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261893971099842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261811052318354 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261728616375261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261646699076969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261565399730020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261484815772668 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261404984862872 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261325866567061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261247370182107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261169408400172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261091943835720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261015002701072 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260938651070938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260862950855832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260787922452636 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260713534621117 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260639724677898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260566434589395 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260493640926571 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260421362277109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260349642105478 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260278519183399 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260208003586474 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260138071338727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260068678926558 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259999787506353 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259931382119922 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259863475497415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259796095791675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259729266772719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259662992459188 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259597254477387 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259532022405880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259467269967675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259402987308798 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259339182775254 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259275874203460 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259213075690149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259150787791915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259088996382714 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259027679973564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258966820514461 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258906411207566 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258846457188056 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258786969381471 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258727955689330 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258669414766583 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258611335670019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258553703004689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258496504110965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258439734013693 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258383395542297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258327495024389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258272036428688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258217017432899 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258162429460645 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258108261279416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258054503769948 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258001153045572 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257948210311689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257895678862865 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257843560201018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257791851563622 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257740546127380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257689635510787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257639112930844 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257588975158241 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257539222278279 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257489855607041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257440875125417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257392277934328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257344058508347 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257296210428288 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257248728465041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257201609797479 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257154853757476 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257108460390271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257062428762739 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257016756004299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256971437553319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256926468351536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256881844215979 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256837562592283 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256793622322033 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256750022652212 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256706762122829 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256663837975901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256621246370333 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256578983202066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256537045004867 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256495429412504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256454134962646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256413160417908 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256372504036390 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256332163210623 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256292134643847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256252414911091 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256213001048974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256173890836571 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256135082637957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256096574938458 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256058365867618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256020452980878 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255982833398574 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255945504188439 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255908462750689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255871706986770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255835235177001 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255799045664883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255763136546019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255727505537710 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255692150085544 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255657067623312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255622255823664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 1.255587712698103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255553436504142 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255519425531066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255485677897667 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255452191475526 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255418963969069 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255385993091604 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255353276728000 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255320812992884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255288600161469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255256636524595 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255224920257613 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255193449376107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255162221795052 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255131235447688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255100488390736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255069978837518 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255039705107129 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255009665526645 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254979858346393 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254950281715029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254920933722687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254891812481008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254862916190962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254834243161103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254805791770653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254777560403721 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254749547394703 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254721751014755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254694169502917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254666801119833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254639644191303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254612697117884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254585958348350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254559426335534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254533099501280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254506976229470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254481054888269 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254455333866072 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254429811599371 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254404486577424 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254379357323325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254354422364435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254329680209973 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254305129347707 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254280768259729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254256595446449 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254232609444322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254208808827824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254185192196026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254161758152858 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254138505292804 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254115432199601 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254092537457343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254069819666435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254047277454824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254024909478546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254002714412265 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253980690936121 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253958837726637 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253937153456447 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253915636802045 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253894286454377 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253873101125899 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253852079550436 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253831220476540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253810522658748 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253789984851820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253769605810938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253749384297094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253729319084081 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253709408962914 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253689652741379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253670049239402 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253650597283234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253631295701831 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253612143327211 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253593138998188 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253574281564968 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253555569891887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253537002856879 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253518579348251 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253500298260826 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253482158493658 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253464158950437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253446298542040 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253428576189549 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253410990825924 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253393541395491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253376226851698 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253359046154564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253341998269238 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253325082166366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253308296823833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253291641228726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253275114378338 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253258715279731 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253242442948165 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253226296405413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253210274678854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253194376801775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253178601814550 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253162948765906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253147416713525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253132004723661 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253116711870066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253101537232861 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253086479897964 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253071538957328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253056713509732 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253042002661584 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253027405527278 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253012921228876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252998548895361 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252984287661886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252970136669413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252956095064887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252942162001754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252928336640480 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252914618148738 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252901005701157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252887498478807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252874095668687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252860796463497 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252847600061761 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252834505668159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252821512493860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252808619756605 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252795826680513 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252783132495721 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252770536438033 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252758037748774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252745635674868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252733329469055 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252721118390088 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252709001702763 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252696978677774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252685048591445 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252673210725501 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252661464366957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252649808808180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252638243347009 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252626767286878 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252615379936814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252604080611317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252592868630174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252581743318295 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252570704005638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252559750027233 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252548880723267 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252538095439141 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252527393525452 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252516774337901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252506237237156 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252495781588730 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252485406762932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252475112134869 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252464897084496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252454760996640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252444703260972 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252434723271932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252424820428629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252414994134751 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252405243798523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252395568832700 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252385968654596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252376442686076 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252366990353539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252357611087847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252348304324252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252339069502322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252329906065915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252320813463159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252311791146459 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252302838572492 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252293955202174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252285140500603 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252276393937008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252267714984688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252259103120981 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252250557827250 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252242078588877 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252233664895247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252225316239716 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252217032119571 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252208812035976 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252200655493928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252192562002234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252184531073484 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252176562224047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252168654974044 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252160808847325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252153023371426 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252145298077530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252137632500429 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252130026178498 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252122478653677 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252114989471448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252107558180820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252100184334301 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252092867487859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252085607200892 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252078403036194 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252071254559928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252064161341611 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252057122954088 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252050138973516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252043208979334 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252036332554236 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252029509284136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252022738758144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252016020568543 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252009354310760 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252002739583356 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251996175988002 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251989663129448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251983200615506 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251976788057012 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251970425067809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251964111264721 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251957846267532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251951629698969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251945461184676 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251939340353196 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251933266835944 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251927240267181 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251921260283994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251915326526272 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251909438636687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251903596260675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251897799046415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251892046644808 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251886338709453 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251880674896626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251875054865257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251869478276915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251863944795779 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251858454088627 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251853005824819 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251847599676265 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251842235317415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251836912425235 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251831630679184 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251826389761203 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251821189355686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251816029149470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251810908831814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251805828094378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251800786631207 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251795784138712 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251790820315646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251785894863094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251781007484448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251776157885396 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251771345773901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251766570860183 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251761832856703 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251757131478144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251752466441394 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251747837465530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251743244271798 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251738686583600 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251734164126480 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251729676628099 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251725223818227 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251720805428719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251716421193505 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251712070848573 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251707754131946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251703470783678 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251699220545830 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251695003162458 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251690818379596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251686665945242 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251682545609340 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251678457123767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251674400242320 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251670374720697 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251666380316486 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251662416789149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251658483900007 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251654581412226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251650709090801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251646866702546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251643054016076 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251639270801796 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251635516831885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251631791880282 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251628095722676 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251624428136488 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251620788900860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251617177796640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251613594606374 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251610039114283 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251606511106262 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251603010369856 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251599536694256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251596089870281 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251592669690368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251589275948554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251585908440475 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251582566963343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251579251315936 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251575961298591 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251572696713187 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251569457363134 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251566243053361 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251563053590307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251559888781905 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251556748437574 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251553632368207 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251550540386157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251547472305228 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251544427940664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251541407109136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251538409628734 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251535435318952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251532484000681 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251529555496195 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251526649629144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251523766224540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251520905108745 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251518066109470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251515249055749 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251512453777945 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251509680107730 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251506927878074 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251504196923243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251501487078781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251498798181504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251496130069490 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251493482582068 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251490855559810 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251488248844519 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251485662279221 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251483095708156 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251480548976770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251478021931699 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251475514420767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251473026292977 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251470557398495 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251468107588647 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251465676715908 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251463264633895 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251460871197353 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251458496262153 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251456139685279 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251453801324820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251451481039963 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251449178690984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251446894139237 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251444627247148 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251442377878209 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251440145896964 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251437931169007 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251435733560967 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251433552940509 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251431389176318 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251429242138094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251427111696545 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251424997723378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251422900091292 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251420818673970 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251418753346072 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251416703983224 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251414670462017 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251412652659996 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251410650455649 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251408663728406 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251406692358630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251404736227605 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251402795217537 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251400869211539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251398958093630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251397061748723 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251395180062626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251393312922021 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251391460214475 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251389621828416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251387797653143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251385987578802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251384191496396 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251382409297764 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251380640875585 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251378886123367 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251377144935440 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251375417206952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251373702833862 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251372001712930 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251370313741719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251368638818580 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251366976842650 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251365327713848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251363691332866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251362067601161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251360456420955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251358857695223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251357271327694 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251355697222837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251354135285861 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251352585422709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251351047540048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251349521545271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251348007346482 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251346504852499 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251345013972843 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251343534617736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251342066698091 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251340610125512 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251339164812286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251337730671379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251336307616426 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251334895561735 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251333494422272 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251332104113663 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251330724552185 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251329355654759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251327997338957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251326649522979 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251325312125663 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251323985066471 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251322668265490 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251321361643422 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251320065121586 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251318778621904 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251317502066908 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251316235379722 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251314978484070 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251313731304262 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251312493765193 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251311265792343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251310047311762 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251308838250074 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251307638534473 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251306448092713 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251305266853105 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251304094744518 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251302931696368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251301777638618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251300632501773 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251299496216871 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251298368715489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251297249929729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251296139792219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251295038236108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251293945195061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251292860603256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251291784395383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251290716506629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251289656872691 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251288605429758 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251287562114512 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251286526864127 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251285499616260 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251284480309054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251283468881124 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251282465271566 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251281469419942 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251280481266282 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251279500751083 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251278527815298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251277562400338 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251276604448067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251275653900797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251274710701289 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251273774792744 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251272846118803 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251271924623540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251271010251466 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251270102947517 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251269202657058 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251268309325873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251267422900166 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251266543326558 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251265670552085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251264804524185 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251263945190709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251263092499908 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251262246400435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251261406841339 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251260573772061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251259747142436 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251258926902684 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251258113003413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251257305395608 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251256504030639 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251255708860247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251254919836547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251254136912026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251253360039538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251252589172298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251251824263887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251251065268243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251250312139660 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251249564832785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251248823302616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251248087504500 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251247357394126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251246632927531 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251245914061084 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251245200751498 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251244492955819 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251243790631423 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251243093736018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251242402227637 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251241716064638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251241035205701 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251240359609825 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251239689236328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251239024044840 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251238363995302 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251237709047969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251237059163401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251236414302461 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251235774426317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251235139496436 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251234509474584 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251233884322821 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251233264003502 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251232648479271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251232037713062 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251231431668095 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251230830307877 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251230233596192 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251229641497106 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251229053974967 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251228470994393 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251227892520277 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251227318517785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251226748952350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251226183789675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251225622995726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251225066536732 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251224514379184 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251223966489832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251223422835682 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251222883383996 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251222348102290 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251221816958328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251221289920126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251220766955947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251220248034297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251219733123929 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251219222193835 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251218715213246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251218212151635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251217712978705 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251217217664398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251216726178887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251216238492575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251215754576094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251215274400303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251214797936286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251214325155352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251213856029030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251213390529068 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251212928627437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251212470296321 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251212015508118 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251211564235444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251211116451122 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251210672128187 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251210231239883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251209793759659 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251209359661172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251208928918280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251208501505045 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251208077395727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251207656564788 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251207238986886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251206824636876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251206413489804 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251206005520912 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251205600705632 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251205199019588 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251204800438590 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251204404938636 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251204012495910 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251203623086778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251203236687792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251202853275682 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251202472827361 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251202095319917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251201720730618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251201349036906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251200980216398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251200614246885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251200251106328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251199890772861 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251199533224782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251199178440560 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251198826398833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251198477078401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251198130458225 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251197786517435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251197445235318 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251197106591324 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251196770565058 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251196437136286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251196106284929 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251195777991064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251195452234922 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251195128996884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251194808257488 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251194489997417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251194174197506 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251193860838740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251193549902247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251193241369302 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251192935221328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251192631439887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251192330006686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251192030903574 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251191734112539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251191439615708 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251191147395347 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251190857433859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251190569713782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251190284217792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251190000928694 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251189719829430 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251189440903073 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251189164132825 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251188889502021 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251188616994120 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251188346592716 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251188078281522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251187812044384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251187547865266 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251187285728262 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251187025617585 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251186767517573 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251186511412681 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251186257287489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251186005126693 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251185754915107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251185506637666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251185260279417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251185015825525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251184773261270 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251184532572045 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251184293743355 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251184056760818 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251183821610164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251183588277232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251183356747971 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251183127008440 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182899044802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182672843330 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182448390403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182225672504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182004676222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251181785388249 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251181567795378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251181351884508 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251181137642635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180925056859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180714114378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180504802489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180297108587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180091020167 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179886524816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179683610222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179482264163 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179282474516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179084229250 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178887516426 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178692324199 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178498640813 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178306454606 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178115754006 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177926527527 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177738763775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177552451441 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177367579309 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177184136245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177002111201 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176821493217 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176642271415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176464435005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176287973275 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176112875600 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175939131435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175766730319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175595661868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175425915783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175257481841 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175090349898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174924509890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174759951832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174596665811 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174434641998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174273870634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174114342037 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173956046602 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173798974795 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173643117159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173488464307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173335006927 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173182735777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173031641689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172881715562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172732948370 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172585331152 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172438855020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172293511154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172149290800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172006185275 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171864185959 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171723284303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171583471821 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171444740096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171307080769 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171170485554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171034946225 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170900454619 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170767002638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170634582244 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170503185464 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170372804386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170243431158 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170115057989 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169987677149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169861280967 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169735861831 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169611412189 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169487924547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169365391469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169243805575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169123159544 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169003446111 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168884658067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168766788257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168649829586 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168533775008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168418617537 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168304350236 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168190966225 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168078458677 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167966820816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167856045918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167746127314 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167637058385 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167528832561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167421443327 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167314884216 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167209148809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167104230740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167000123692 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166896821395 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166794317627 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166692606217 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166591681041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166491536018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166392165120 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166293562362 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166195721807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166098637562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166002303781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165906714664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165811864453 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165717747439 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165624357951 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165531690368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165439739107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165348498634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165257963451 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165168128108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165078987196 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164990535346 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164902767232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164815677567 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164729261109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164643512653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164558427035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164473999132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164390223859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164307096172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164224611064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164142763569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164061548758 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163980961740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163900997662 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163821651709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163742919103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163664795102 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163587275003 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163510354136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163434027870 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163358291609 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163283140791 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163208570892 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163134577421 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163061155921 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162988301972 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162916011186 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162844279210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162773101725 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162702474444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162632393115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162562853516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162493851460 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162425382794 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162357443391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162290029162 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162223136048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162156760019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162090897080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162025543263 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161960694633 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161896347285 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161832497344 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161769140966 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161706274334 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161643893664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161581995197 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161520575209 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161459629998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161399155896 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161339149261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161279606479 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161220523965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161161898161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161103725534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161046002585 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160988725837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160931891840 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160875497171 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160819538434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160764012261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160708915307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160654244254 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160599995809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160546166707 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160492753706 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160439753589 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160387163165 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160334979266 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160283198751 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160231818500 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160180835422 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160130246442 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160080048519 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160030238626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159980813766 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159931770961 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159883107259 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159834819729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159786905462 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159739361575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159692185204 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159645373507 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159598923666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159552832884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159507098386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159461717417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159416687243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159372005155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159327668461 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159283674491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159240020595 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159196704145 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159153722534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159111073170 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159068753489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159026760939 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158985092994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158943747143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158902720898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158862011785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158821617356 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158781535177 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158741762835 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158702297934 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158663138098 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158624280969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158585724206 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158547465490 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158509502514 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158471832992 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158434454658 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158397365259 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158360562562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158324044352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158287808429 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158251852610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158216174731 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158180772643 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158145644215 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158110787330 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158076199890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158041879812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158007825030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157974033491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157940503164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157907232026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157874218075 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157841459323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157808953797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157776699540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157744694610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157712937078 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157681425034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157650156578 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157619129830 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157588342918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157557793990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157527481207 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157497402743 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157467556785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157437941538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157408555218 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157379396055 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157350462293 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157321752191 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157293264018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157264996059 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157236946614 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157209113991 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157181496515 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157154092523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157126900365 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157099918404 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157073145013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157046578582 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157020217510 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156994060210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156968105107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156942350638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156916795252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156891437409 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156866275583 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156841308259 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156816533934 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156791951115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156767558322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156743354086 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156719336949 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156695505465 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156671858200 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156648393730 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156625110639 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156602007528 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156579083005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156556335689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156533764211 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156511367211 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156489143340 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156467091260 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156445209644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156423497174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156401952541 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156380574450 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156359361612 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156338312749 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156317426595 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156296701891 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156276137391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156255731855 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156235484054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156215392769 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156195456790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156175674917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156156045959 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156136568733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156117242067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156098064797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156079035767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156060153833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156041417856 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156022826709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156004379273 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155986074435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155967911094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155949888156 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155932004537 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155914259159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155896650954 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155879178859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155861841825 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155844638807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155827568768 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155810630682 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155793823527 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155777146293 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155760597973 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155744177573 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155727884103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155711716582 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155695674036 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155679755501 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155663960015 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155648286630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155632734400 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155617302389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155601989670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155586795317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155571718416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155556758061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155541913350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155527183389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155512567292 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155498064177 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155483673171 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155469393409 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155455224029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155441164180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155427213013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155413369689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155399633375 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155386003244 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155372478472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155359058248 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155345741763 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155332528216 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155319416809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155306406753 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155293497266 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155280687569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155267976892 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155255364469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155242849540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155230431352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155218109157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155205882213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155193749783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155181711138 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155169765552 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155157912306 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155146150685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155134479983 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155122899494 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155111408525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155100006380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155088692374 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155077465826 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155066326060 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155055272403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155044304192 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155033420767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155022621470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155011905652 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155001272668 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154990721877 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154980252644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154969864338 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154959556335 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154949328013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154939178756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154929107952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154919114998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154909199288 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154899360227 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154889597223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154879909686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154870297035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154860758690 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154851294077 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154841902625 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154832583770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154823336949 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154814161607 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154805057191 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154796023152 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154787058946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154778164034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154769337880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154760579953 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154751889724 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154743266671 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154734710276 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154726220021 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154717795395 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154709435892 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154701141010 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154692910246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154684743106 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154676639099 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154668597736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154660618534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154652701010 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154644844689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154637049098 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154629313768 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154621638231 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154614022026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154606464696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154598965782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154591524837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154584141410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154576815057 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154569545337 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154562331812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154555174048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154548071615 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154541024082 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154534031027 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154527092029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154520206670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154513374536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154506595213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154499868295 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154493193376 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154486570053 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154479997930 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154473476610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154467005700 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154460584810 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154454213554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154447891547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154441618410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154435393765 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154429217237 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154423088452 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154417007043 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154410972645 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154404984893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154399043425 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154393147886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154387297919 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154381493172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154375733297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154370017946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154364346774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154358719441 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154353135608 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154347594937 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154342097097 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154336641754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154331228581 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154325857252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154320527444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154315238836 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154309991109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154304783947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154299617036 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154294490066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154289402727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154284354714 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154279345723 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154274375450 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154269443598 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154264549869 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154259693970 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154254875606 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154250094489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154245350329 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154240642842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154235971744 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154231336754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154226737593 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154222173983 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154217645650 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154213152321 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154208693727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154204269596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154199879664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154195523667 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154191201342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154186912429 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154182656669 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154178433806 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154174243586 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154170085756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154165960068 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154161866270 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154157804118 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154153773365 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154149773772 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154145805095 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154141867096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154137959538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154134082185 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154130234805 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154126417165 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154122629036 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154118870188 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154115140397 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154111439437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154107767085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154104123122 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154100507325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154096919480 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154093359369 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154089826776 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154086321492 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154082843303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154079392001 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154075967378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154072569226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154069197342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154065851524 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154062531569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154059237277 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154055968450 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154052724891 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154049506405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154046312799 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154043143878 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154039999454 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154036879335 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154033783337 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154030711269 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154027662950 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154024638193 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154021636818 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154018658644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154015703491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154012771182 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154009861540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154006974389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154004109556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154001266868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153998446154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153995647245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153992869971 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153990114164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153987379662 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153984666297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153981973906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153979302328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153976651400 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153974020965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153971410863 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153968820937 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153966251031 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153963700991 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153961170663 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153958659893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153956168532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153953696431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153951243438 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153948809407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153946394191 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153943997646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153941619624 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153939259986 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153936918587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153934595288 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153932289947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153930002428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153927732590 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153925480299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153923245417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153921027812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153918827349 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153916643895 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153914477319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153912327492 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153910194282 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153908077563 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153905977205 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153903893083 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153901825072 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153899773047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153897736884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153895716460 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153893711654 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153891722345 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153889748414 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153887789742 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153885846210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153883917701 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153882004101 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153880105291 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153878221161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153876351594 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153874496479 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153872655705 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153870829161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153869016733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153867218318 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153865433803 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153863663084 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153861906052 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153860162602 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153858432629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153856716027 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153855012697 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153853322532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153851645433 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153849981298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153848330026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153846691520 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153845065678 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153843452405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153841851602 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153840263173 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153838687024 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153837123057 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153835571180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153834031299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153832503322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153830987155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153829482710 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153827989893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153826508616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153825038789 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153823580324 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153822133133 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153820697129 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153819272224 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153817858336 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153816455376 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153815063261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153813681907 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153812311231 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153810951151 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153809601583 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153808262448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153806933665 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153805615154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153804306833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153803008627 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153801720456 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153800442243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153799173909 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153797915380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153796666580 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153795427433 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153794197866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153792977801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153791767169 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153790565894 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153789373906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153788191132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153787017500 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153785852941 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153784697384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153783550759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153782412998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153781284032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153780163792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153779052212 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153777949226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153776854764 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153775768763 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153774691157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153773621881 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153772560870 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153771508061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153770463391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153769426795 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153768398213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153767377581 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153766364839 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153765359925 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153764362780 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153763373342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153762391554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153761417354 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153760450684 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153759491488 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153758539705 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153757595280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153756658155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153755728275 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153754805582 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153753890022 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153752981539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153752080080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153751185587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153750298010 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153749417293 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153748543385 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153747676232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153746815782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153745961984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153745114785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153744274135 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153743439984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153742612280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153741790974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153740976017 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153740167360 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153739364955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153738568751 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153737778702 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153736994760 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153736216879 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153735445010 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153734679107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153733919126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153733165019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153732416741 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153731674247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153730937492 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153730206434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153729481026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153728761226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153728046990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153727338274 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153726635037 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153725937236 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153725244829 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153724557775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153723876032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153723199558 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153722528313 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153721862257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153721201351 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153720545552 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153719894823 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153719249125 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153718608417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153717972662 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153717341822 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153716715858 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153716094733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153715478408 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153714866848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153714260016 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153713657875 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153713060388 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153712467520 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153711879234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153711295496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153710716270 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153710141522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153709571217 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153709005320 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153708443797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153707886616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153707333740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153706785139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153706240778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153705700626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153705164649 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153704632815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153704105092 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153703581449 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153703061852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153702546273 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153702034679 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153701527039 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153701023324 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153700523503 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153700027546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153699535422 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153699047101 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153698562556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153698081756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153697604674 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153697131278 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153696661542 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153696195437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153695732936 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153695274009 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153694818630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153694366771 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153693918404 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153693473505 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153693032044 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153692593995 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153692159332 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153691728030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153691300061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153690875401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153690454023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153690035903 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153689621015 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153689209333 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153688800835 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153688395493 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153687993285 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153687594186 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153687198172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153686805220 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153686415305 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153686028403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153685644493 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153685263550 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153684885554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153684510477 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153684138300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153683769001 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153683402556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153683038943 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153682678142 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153682320129 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153681964884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153681612385 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153681262610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153680915540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153680571153 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153680229427 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153679890343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153679553880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 1.251153679220018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153678888737 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153678560017 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153678233837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153677910179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153677589023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153677270350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153676954139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153676640373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153676329033 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153676020099 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153675713554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153675409377 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153675107552 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153674808061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153674510884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153674216005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153673923404 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153673633066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153673344972 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153673059105 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153672775448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153672493984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153672214695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153671937565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153671662577 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153671389716 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153671118962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153670850302 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153670583720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153670319198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153670056720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153669796271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153669537836 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153669281398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153669026944 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153668774455 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153668523918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153668275317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153668028639 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153667783868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153667540988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153667299987 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153667060848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153666823557 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153666588101 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153666354466 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153666122635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153665892597 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153665664337 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153665437842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153665213098 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664990090 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664768807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664549234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664331359 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664115166 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663900646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663687785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663476568 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663266985 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663059020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662852664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662647903 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662444725 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662243117 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662043068 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661844565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661647597 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661452151 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661258215 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661065780 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660874832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660685359 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660497352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660310797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660125685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659942003 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659759741 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659578889 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659399434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659221367 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659044677 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658869351 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658695381 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658522756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658351465 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658181499 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658012846 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657845496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657679441 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657514669 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657351171 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657188937 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657027957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656868221 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656709719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656552444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656396384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656241530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656087873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655935405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655784114 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655633993 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655485032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655337223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655190557 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655045025 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654900617 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654757325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654615141 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654474057 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654334062 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654195151 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654057312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653920540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653784824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653650158 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653516532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653383940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653252372 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653121822 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652992280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652863741 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652736194 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652609634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652484052 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652359440 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652235793 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652113100 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651991356 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651870553 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651750684 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651631743 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651513719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651396609 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651280403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651165096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651050680 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650937149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650824495 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650712712 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650601794 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650491732 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650382522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650274155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650166626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650059929 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649954056 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649849002 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649744759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649641323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649538686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649436843 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649335786 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649235511 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649136011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649037280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648939312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648842102 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648745643 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648649930 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648554956 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648460718 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648367206 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648274418 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648182347 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648090988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648000336 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647910383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647821126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647732560 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647644678 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647557475 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647470946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647385087 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647299891 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647215352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647131469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647048233 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646965640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646883687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646802366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646721675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646641606 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646562158 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646483323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646405097 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646327477 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646250455 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646174030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646098196 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646022947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645948281 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645874191 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645800674 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645727726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645655341 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645583515 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645512246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645441527 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645371354 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645301724 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645232632 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645164075 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645096047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645028546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644961565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644895103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644829154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644763715 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644698783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644634351 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644570419 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644506980 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644444032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644381570 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644319591 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644258092 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644197067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644136515 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644076430 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644016810 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643957650 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643898948 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643840700 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643782902 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643725551 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643668643 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643612175 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643556144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643500546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643445377 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643390635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643336316 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643282417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643228935 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643175866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643123206 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643070955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643019107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642967660 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642916611 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642865956 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642815693 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642765819 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642716329 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642667223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642618496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642570146 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642522169 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642474564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642427326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642380453 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642333943 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642287792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642241999 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642196559 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642151471 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642106730 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642062335 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642018284 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641974574 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641931202 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641888164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641845459 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641803085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641761037 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641719315 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641677915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641636836 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641596074 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641555627 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641515493 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641475669 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641436153 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641396941 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641358034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641319427 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641281119 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641243107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641205388 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641167961 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641130824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641093973 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641057407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641021125 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640985122 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640949398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640913950 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640878776 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640843873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640809241 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640774876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640740777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640706942 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640673368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640640053 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640606997 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640574196 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640541647 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640509352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640477305 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640445507 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640413953 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640382644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640351577 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640320750 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640290162 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640259809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640229691 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640199807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640170153 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640140729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640111532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640082561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640053813 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640025289 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639996983 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639968898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639941029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639913376 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639885936 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639858708 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639831691 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639804883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639778282 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639751886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639725695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639699707 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639673919 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639648330 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639622940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639597745 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639572745 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639547939 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639523323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639498900 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639474664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639450615 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639426753 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639403075 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639379580 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639356267 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639333133 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639310179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639287403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639264801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639242375 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639220123 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639198042 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639176132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639154391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639132819 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639111413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639090172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639069096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639048183 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639027431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639006840 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638986408 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638966134 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638946016 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638926055 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638906247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638886592 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638867090 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638847738 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638828536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638809482 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638790575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638771815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638753200 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638734728 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638716400 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638698213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638680167 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638662260 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638644491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638626860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638609365 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638592006 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638574781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638557689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638540728 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638523899 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638507200 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638490630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638474189 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638457875 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638441686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638425622 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638409684 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638393867 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638378174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638362601 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638347149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638331816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638316603 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638301506 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638286525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638271662 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638256913 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638242277 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638227755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638213346 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638199047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638184860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638170782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638156812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638142952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638129197 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638115549 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638102007 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638088569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638075236 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638062005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638048876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638035849 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638022923 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638010096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637997370 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637984741 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637972210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637959775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637947437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637935195 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637923046 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637910991 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637899031 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637887161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637875386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637863699 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637852104 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637840598 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637829181 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637817852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637806611 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637795457 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637784388 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637773406 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637762509 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637751695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637740965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637730319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637719754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637709272 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637698870 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637688548 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637678307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637668144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637658061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637648054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637638126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637628274 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637618498 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637608798 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637599173 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637589622 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637580145 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637570742 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637561411 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637552152 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637542964 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637533848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637524803 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637515827 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637506920 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637498083 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637489313 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637480612 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637471978 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637463410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637454909 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637446473 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637438103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637429798 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637421556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637413378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637405264 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637397212 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637389222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637381295 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637373428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637365622 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637357876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637350192 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637342565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637334998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637327489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637320038 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637312646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637305309 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637298030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637290807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637283641 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637276529 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637269472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637262470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637255522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637248628 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637241787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637234999 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637228263 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637221579 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637214947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637208366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637201837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637195358 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637188929 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637182548 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637176219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637169938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637163705 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637157520 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637151383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637145294 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637139252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637133257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637127307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637121403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637115547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637109734 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637103966 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637098244 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637092565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637086931 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637081339 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637075792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637070286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637064824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637059405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637054026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637048689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637043394 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637038139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637032925 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637027752 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637022618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637017524 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637012469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637007454 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637002478 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636997539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636992638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636987777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636982952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636978165 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636973415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636968701 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636964023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636959383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636954778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636950208 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636945674 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636941175 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636936710 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636932280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636927885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636923523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636919195 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636914901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636910639 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636906411 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636902215 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636898052 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636893921 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636889821 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636885754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636881718 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636877713 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636873740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636869797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636865884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636862002 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636858149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636854326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636850534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636846770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636843035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636839329 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636835652 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636832004 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636828383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636824790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636821226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636817688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636814179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636810696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636807240 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636803811 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636800409 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636797033 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636793682 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636790358 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636787059 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636783787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636780539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636777316 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636774119 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636770945 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636767796 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636764673 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636761572 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636758496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636755444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636752415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636749410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636746428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636743469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636740533 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636737620 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636734729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636731860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636729014 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636726189 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636723386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636720606 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636717847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636715109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636712391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636709696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636707021 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636704367 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636701732 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636699119 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636696525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636693952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636691399 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636688866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636686352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636683857 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636681381 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636678925 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636676489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636674070 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636671670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636669289 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636666927 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636664581 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636662256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636659947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636657656 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636655384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636653129 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636650890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636648670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636646467 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636644280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636642111 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636639959 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636637823 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636635703 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636633600 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636631514 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636629443 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636627388 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636625350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636623326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636621319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636619326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636617350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636615389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636613443 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636611512 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636609596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636607695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636605808 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636603936 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636602078 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636600235 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636598407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636596591 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636594792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636593004 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636591231 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636589472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636587726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636585994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636584275 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636582570 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636580878 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636579198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636577532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636575879 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636574238 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636572610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636570994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636569391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636567801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636566223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636564657 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636563103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636561561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636560031 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636558513 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636557006 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636555511 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636554028 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636552557 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636551096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636549647 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636548209 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636546783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636545366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636543962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636542569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636541185 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636539813 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636538451 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636537099 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636535759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636534428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636533108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636531797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636530498 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636529208 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636527928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636526658 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636525398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636524148 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636522907 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636521676 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636520454 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636519242 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636518039 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636516845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636515661 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636514486 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636513319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636512162 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636511015 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636509876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636508745 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636507624 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636506510 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636505406 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636504310 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636503223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636502144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636501073 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636500011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636498956 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636497911 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636496873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636495842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636494820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636493807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636492800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636491802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636490811 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636489829 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636488852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636487885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636486924 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636485971 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636485025 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636484087 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636483156 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636482232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636481315 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636480406 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636479504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636478608 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636477719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636476837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636475962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636475094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636474232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636473378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636472528 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636471687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636470852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636470023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636469201 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636468385 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636467575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636466771 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636465975 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636465183 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636464398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636463619 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636462847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636462080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636461318 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636460564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636459814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636459071 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636458333 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636457601 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636456875 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636456154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636455439 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636454729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636454025 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636453326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636452633 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636451946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636451263 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636450585 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636449913 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636449246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636448584 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636447927 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636447276 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636446629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636445988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636445351 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636444720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636444093 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636443471 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636442854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636442242 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636441634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636441031 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636440433 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636439839 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636439250 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636438666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636438085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636437511 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636436939 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636436373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636435810 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636435252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636434699 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636434149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636433604 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636433064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636432527 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636431994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636431466 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636430941 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636430421 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636429905 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636429393 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636428884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636428380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636427880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636427383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636426890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636426401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636425917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636425435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636424957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636424483 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636424013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636423546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636423083 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636422623 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636422167 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636421715 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636421266 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636420821 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636420378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636419940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636419504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636419073 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636418644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636418219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636417797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636417379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636416962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636416551 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636416142 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636415736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636415334 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636414934 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636414537 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636414143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636413753 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636413366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636412981 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636412599 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636412221 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636411846 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636411472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636411104 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636410736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636410372 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636410011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636409653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636409297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636408944 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636408593 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636408247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636407901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636407559 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636407219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636406883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636406549 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636406217 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636405888 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636405561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636405237 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636404915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636404596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636404280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636403965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636403654 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636403344 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636403038 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636402733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636402431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636402131 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636401833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636401538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636401245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636400955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636400666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636400379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636400095 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636399814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636399534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636399256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636398981 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636398707 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636398437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636398168 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636397901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636397637 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636397373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636397113 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636396854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636396597 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636396342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636396089 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636395838 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636395590 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636395342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636395097 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636394854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636394613 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636394373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636394135 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636393900 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636393666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636393434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636393204 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392976 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392748 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392078 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636391859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636391641 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636391424 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636391209 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390996 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390784 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390160 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389752 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389549 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389349 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389150 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388953 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388758 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388563 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388370 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387614 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387429 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387063 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386882 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386702 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386524 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386348 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386171 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385997 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385482 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385313 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385146 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384980 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384651 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384327 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384168 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384009 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383851 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383082 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382488 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382197 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381912 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381771 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381353 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381216 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380945 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380679 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380287 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380158 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379903 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379529 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379285 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379043 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378924 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378806 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378572 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378457 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378229 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378116 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378004 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377674 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377457 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376829 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376524 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376425 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376228 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 1.251153636376132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375939 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375843 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375750 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375656 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375563 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375288 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374672 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374502 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374418 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374335 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374170 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374089 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373769 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373691 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373614 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373459 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373308 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372869 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372656 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372586 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372113 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371982 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371665 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371603 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371541 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371481 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371420 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371360 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371240 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371182 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371124 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371065 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370951 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370895 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370838 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370672 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370510 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370458 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370353 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370249 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370147 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369997 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369948 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369900 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369851 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369803 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369708 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369660 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369615 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369568 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369477 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369432 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369387 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369254 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369211 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369168 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369125 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369082 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368999 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368958 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368835 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368795 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368715 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368677 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368637 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368598 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368560 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368484 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368447 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368336 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368264 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368228 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368192 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368123 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368088 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367985 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367919 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367723 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367693 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367661 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367599 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367568 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367507 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367478 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367418 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367359 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367331 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367274 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367218 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367190 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367082 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367055 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367002 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366977 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366951 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366926 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366900 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366874 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366850 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366825 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366751 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366704 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366680 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366657 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366541 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366519 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366497 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366475 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366453 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366409 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366387 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366367 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366345 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366304 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366283 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366262 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366202 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366182 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366163 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366124 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366105 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366028 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365992 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365956 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365920 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365902 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365867 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365850 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365749 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365717 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365701 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365669 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365654 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365623 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365607 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365592 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365577 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365518 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365503 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365474 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365460 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365446 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365432 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365418 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365404 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365390 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365377 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365363 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365337 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365324 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365311 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365285 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365272 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365260 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365248 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365186 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365162 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365150 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365127 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365092 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365081 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365070 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365059 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365037 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365015 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364963 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364953 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364942 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364933 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364923 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364913 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364903 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364864 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364836 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364827 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364818 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364808 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364772 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364764 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364746 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364738 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364713 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364704 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364680 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364671 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364655 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364647 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364631 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364624 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364609 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364602 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364594 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364579 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364572 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364558 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364551 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364543 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364508 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364502 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364495 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364482 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364476 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364462 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364456 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364450 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364426 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364420 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364396 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364372 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364360 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364355 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364349 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364344 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364339 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364333 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364302 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364296 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364291 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364281 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364276 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364267 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364242 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364237 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364233 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364228 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364214 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364206 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364202 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364197 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364193 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364188 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364184 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364175 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364167 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364163 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364151 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364147 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364128 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364123 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364120 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364116 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364112 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364106 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364101 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364098 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364091 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364088 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364084 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364077 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364074 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364071 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364063 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364060 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364057 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364051 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364044 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364038 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364025 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364017 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364014 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364003 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363999 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363996 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363992 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363986 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363983 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363980 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363978 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363975 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363973 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363970 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363967 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363964 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363963 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363959 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363950 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363945 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363942 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363935 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363933 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363931 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363927 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363924 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363922 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363919 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363913 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363911 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363909 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363904 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363902 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363896 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363894 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363891 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363888 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363879 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363877 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363871 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363869 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363864 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363862 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363861 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363857 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363856 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363850 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363849 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363844 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363841 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363839 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363838 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363834 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363830 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363828 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363827 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363826 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363822 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363822 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363818 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363817 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363813 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363805 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363804 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363799 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363796 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363795 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363794 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363793 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363791 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363789 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363784 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363779 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363773 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363772 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363771 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363769 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363766 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363766 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363765 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363764 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363763 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363762 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363761 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363757 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH4pT1cLPq7QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bce0b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from notes_utilities import pnorm_ball_line\n",
    "from IPython import display\n",
    "\n",
    "# initialize data\n",
    "x = np.array([10., 8., 13., 9., 11., 14., 6., 4., 12., 7., 5.])\n",
    "y = np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
    "N = len(x)\n",
    "\n",
    "# create the design matrix\n",
    "A = np.vstack((np.ones(N), x)).T\n",
    "\n",
    "# calculate values using numpy (np) \n",
    "w_best, E, rank, s = np.linalg.lstsq(A, y)\n",
    "print(\"best w (numpy result):\", w_best)\n",
    "\n",
    "# calculate the min value using w_best\n",
    "err = y-A.dot(w_best) \n",
    "E_min = np.sum(err**2) / N\n",
    "print(\"min error (numpy result):\", E_min, \"\\n\")\n",
    "\n",
    "def draw_pnorm():\n",
    "    for i in range(0, 10):\n",
    "        ln = pnorm_ball_line(mu=w_best, A = i*4*np.linalg.cholesky(np.linalg.inv(A.T.dot(A))),linewidth=1)\n",
    "        plt.gca().add_line(ln) \n",
    "\n",
    "\n",
    "\n",
    "def inspect_momentum():\n",
    "\n",
    "    alpha = 0.001\n",
    "    beta = 0.95\n",
    "    learning_rate = 1.1\n",
    "    \n",
    "    # set start position for w\n",
    "    w0 = np.array([2., 1.])\n",
    "    w = w0.copy()\n",
    "    p = 0\n",
    "    E_n = 10000\n",
    "    # set bounds and draw title\n",
    "    plt.title('alpha = '+ str(alpha) + ' beta = ' +str(beta))\n",
    "    plt.xlim((1.8,4.3))\n",
    "    plt.ylim((0,1.2))\n",
    "    \n",
    "    # draw start position\n",
    "    plt.plot(w[0],w[1],'ko')\n",
    "    \n",
    "    # draw best position\n",
    "    plt.plot(w_best[0],w_best[1],'ro')\n",
    "    \n",
    "    EPOCHS = 100000000\n",
    "    # create a 2 * EPOCHS array\n",
    "    W = np.zeros((2,EPOCHS))\n",
    "\n",
    "    i  =0\n",
    "    while True:\n",
    "        # Error\n",
    "        err = y-A.dot(w)\n",
    "        W[:,i] = w\n",
    "        \n",
    "        # Mean square error\n",
    "        E = np.sum(err**2) / N\n",
    "        \n",
    "        if E > E_n:\n",
    "            alpha = alpha / learning_rate\n",
    "            learning_rate = 1 + (learning_rate - 1) / 2\n",
    "        elif E_n == E:\n",
    "            break\n",
    "        else:\n",
    "            E_n = E\n",
    "            print(\"error: %8.15f | alpha: %8.15f | learning rate: %8.15f\" % (E, alpha, learning_rate))\n",
    "\n",
    "        # Gradient\n",
    "        dE = -2. * A.T.dot(err) / N\n",
    "        p = dE + beta * p\n",
    " \n",
    "        # Perfom one descent step\n",
    "        w = w - alpha * p \n",
    "        i= i +1\n",
    "    return W\n",
    "\n",
    "# run solution\n",
    "draw_pnorm()\n",
    "\n",
    "inspect_momentum()\n",
    "\n",
    "        \n",
    "# draw solution\n",
    "plt.plot(W[0,:],W[1,:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
