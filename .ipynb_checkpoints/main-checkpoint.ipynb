{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best w (numpy result): [ 3.00009091  0.50009091]\n",
      "min error (numpy result): 1.25115363636 \n",
      "\n",
      "error: 15.993881818181819 | alpha: 0.001000000000000 | learning rate: 1.100000000000000\n",
      "error: 11.112501245887605 | alpha: 0.001000000000000 | learning rate: 1.100000000000000\n",
      "error: 4.904173700057307 | alpha: 0.001000000000000 | learning rate: 1.100000000000000\n",
      "error: 1.495780331088420 | alpha: 0.001000000000000 | learning rate: 1.100000000000000\n",
      "error: 1.375828233608209 | alpha: 0.000825201702859 | learning rate: 1.000781250000000\n",
      "error: 1.369296137839704 | alpha: 0.000823913667101 | learning rate: 1.000000000000001\n",
      "error: 1.368551141532561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.361282665670135 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.349315554048530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.336920939557256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.328411416603352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.322108812303618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.317073859628759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.312789194829180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.308974733832064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.305481417521842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.305008277385969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.302230920098890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.300913953985659 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.299182022722564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.297416432555386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.296312258744376 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.294338576308774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.293608170008988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.293031400525009 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.291569871784540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.291060325777020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.290065997148115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.289040572050780 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.288660911465683 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.288403274328034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.287445872388685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.286705811894264 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.286402658944733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.285799781801352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.285088249544358 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.284535891520374 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.284278445061689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.284272905904685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.283977093819323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.283481444376108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282938184657428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282510360361141 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282281199552687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282214619044793 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282187305376598 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.282067182227481 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.281789202414809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.281385704758815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280958534737535 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280614431582354 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280403938398555 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280298167166623 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280212916210556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.280061833839368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.279805619753198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.279469723143039 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.279123563350293 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278836819220957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278639833645980 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278510206915616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278390635231692 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.278224822577239 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.277989319725419 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.277703615235300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.277414871061978 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.277168439170768 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276982280632862 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276839426738401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276701002178650 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276530413350736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276313883574856 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.276066035329596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275818808855925 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275601631760472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275424948618069 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275276131768046 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.275128887208658 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274959500898147 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274760036901451 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274541293128416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274324835572125 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.274129697351422 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273961812523122 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273811915517902 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273662273099497 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273497566520978 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273313342374042 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.273117472365320 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272924475053990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272746618556831 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272587168288298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272439403257505 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272291396844078 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.272133286380525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271962662568660 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271785202938963 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271610653493921 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271446892953320 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271295635753664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271152053051434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.271008144843979 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270857583410990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270699135419428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270536858837912 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270377277342014 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270225430745583 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.270082152868220 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269944002278203 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269805626563815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269662980870554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269515490527676 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269366033178240 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269218963151916 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.269077490350909 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268941964359748 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268809949478845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268677873474695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268543160755717 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268405591922389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268267193420364 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.268130863244138 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267998635992974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267870607217220 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267745063327562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267619625785258 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267492661222559 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267364131161384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267235453656966 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.267108551735424 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266984708030773 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266863894638546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266744912235038 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266626180591915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266506668267911 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266386420202008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266266422943131 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266147948593311 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.266031800675177 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265917899540670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265805409542259 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265693282960063 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265580871310464 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265468250479202 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265356103030706 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265245267671048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265136244047064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.265028938318107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264922770441292 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264817047006105 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264711362101094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264605795941890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264500818234529 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264396979914115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264294588864832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264193555248154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.264093477695709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263993897957876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263894563041452 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263795545313106 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263697166244294 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263599786225570 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263503592812248 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263408507748485 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263314253962849 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263220528910254 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263127175500081 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.263034253824477 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262941982644615 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262850596546343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262760208067444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262670752569809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262582039079874 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262493867907439 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262406141769759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262318907978407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262232314464213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262146513001640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.262061569711448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261977432931635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261893971099842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261811052318354 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261728616375261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261646699076969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261565399730020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261484815772668 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261404984862872 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261325866567061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261247370182107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261169408400172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261091943835720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.261015002701072 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260938651070938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260862950855832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260787922452636 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260713534621117 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260639724677898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260566434589395 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260493640926571 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260421362277109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260349642105478 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260278519183399 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260208003586474 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260138071338727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.260068678926558 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259999787506353 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259931382119922 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259863475497415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259796095791675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259729266772719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259662992459188 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259597254477387 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259532022405880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259467269967675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259402987308798 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259339182775254 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259275874203460 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259213075690149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259150787791915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259088996382714 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.259027679973564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258966820514461 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258906411207566 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258846457188056 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258786969381471 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258727955689330 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258669414766583 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258611335670019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258553703004689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258496504110965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258439734013693 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258383395542297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258327495024389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258272036428688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258217017432899 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258162429460645 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258108261279416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258054503769948 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.258001153045572 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257948210311689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257895678862865 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257843560201018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257791851563622 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257740546127380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257689635510787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257639112930844 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257588975158241 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257539222278279 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257489855607041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257440875125417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257392277934328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257344058508347 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257296210428288 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257248728465041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257201609797479 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257154853757476 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257108460390271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257062428762739 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.257016756004299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256971437553319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256926468351536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256881844215979 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256837562592283 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256793622322033 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256750022652212 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256706762122829 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256663837975901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256621246370333 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256578983202066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256537045004867 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256495429412504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256454134962646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256413160417908 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256372504036390 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256332163210623 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256292134643847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256252414911091 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256213001048974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256173890836571 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256135082637957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256096574938458 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256058365867618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.256020452980878 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255982833398574 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255945504188439 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255908462750689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255871706986770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255835235177001 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255799045664883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255763136546019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255727505537710 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255692150085544 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255657067623312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 1.255622255823664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255587712698103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255553436504142 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255519425531066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255485677897667 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255452191475526 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255418963969069 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255385993091604 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255353276728000 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255320812992884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255288600161469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255256636524595 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255224920257613 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255193449376107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255162221795052 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255131235447688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255100488390736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255069978837518 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255039705107129 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.255009665526645 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254979858346393 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254950281715029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254920933722687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254891812481008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254862916190962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254834243161103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254805791770653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254777560403721 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254749547394703 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254721751014755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254694169502917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254666801119833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254639644191303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254612697117884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254585958348350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254559426335534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254533099501280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254506976229470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254481054888269 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254455333866072 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254429811599371 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254404486577424 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254379357323325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254354422364435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254329680209973 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254305129347707 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254280768259729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254256595446449 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254232609444322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254208808827824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254185192196026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254161758152858 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254138505292804 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254115432199601 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254092537457343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254069819666435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254047277454824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254024909478546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.254002714412265 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253980690936121 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253958837726637 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253937153456447 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253915636802045 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253894286454377 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253873101125899 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253852079550436 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253831220476540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253810522658748 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253789984851820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253769605810938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253749384297094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253729319084081 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253709408962914 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253689652741379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253670049239402 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253650597283234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253631295701831 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253612143327211 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253593138998188 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253574281564968 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253555569891887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253537002856879 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253518579348251 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253500298260826 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253482158493658 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253464158950437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253446298542040 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253428576189549 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253410990825924 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253393541395491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253376226851698 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253359046154564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253341998269238 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253325082166366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253308296823833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253291641228726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253275114378338 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253258715279731 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253242442948165 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253226296405413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253210274678854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253194376801775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253178601814550 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253162948765906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253147416713525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253132004723661 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253116711870066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253101537232861 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253086479897964 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253071538957328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253056713509732 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253042002661584 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253027405527278 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.253012921228876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252998548895361 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252984287661886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252970136669413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252956095064887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252942162001754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252928336640480 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252914618148738 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252901005701157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252887498478807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252874095668687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252860796463497 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252847600061761 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252834505668159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252821512493860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252808619756605 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252795826680513 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252783132495721 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252770536438033 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252758037748774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252745635674868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252733329469055 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252721118390088 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252709001702763 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252696978677774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252685048591445 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252673210725501 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252661464366957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252649808808180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252638243347009 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252626767286878 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252615379936814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252604080611317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252592868630174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252581743318295 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252570704005638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252559750027233 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252548880723267 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252538095439141 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252527393525452 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252516774337901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252506237237156 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252495781588730 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252485406762932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252475112134869 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252464897084496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252454760996640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252444703260972 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252434723271932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252424820428629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252414994134751 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252405243798523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252395568832700 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252385968654596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252376442686076 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252366990353539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252357611087847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252348304324252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252339069502322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252329906065915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252320813463159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252311791146459 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252302838572492 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252293955202174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252285140500603 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252276393937008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252267714984688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252259103120981 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252250557827250 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252242078588877 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252233664895247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252225316239716 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252217032119571 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252208812035976 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252200655493928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252192562002234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252184531073484 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252176562224047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252168654974044 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252160808847325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252153023371426 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252145298077530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252137632500429 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252130026178498 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252122478653677 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252114989471448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252107558180820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252100184334301 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252092867487859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252085607200892 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252078403036194 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252071254559928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252064161341611 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252057122954088 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252050138973516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252043208979334 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252036332554236 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252029509284136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252022738758144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252016020568543 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252009354310760 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.252002739583356 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251996175988002 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251989663129448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251983200615506 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251976788057012 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251970425067809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251964111264721 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251957846267532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251951629698969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251945461184676 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251939340353196 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251933266835944 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251927240267181 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251921260283994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251915326526272 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251909438636687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251903596260675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251897799046415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251892046644808 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251886338709453 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251880674896626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251875054865257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251869478276915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251863944795779 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251858454088627 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251853005824819 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251847599676265 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251842235317415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251836912425235 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251831630679184 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251826389761203 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251821189355686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251816029149470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251810908831814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251805828094378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251800786631207 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251795784138712 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251790820315646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251785894863094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251781007484448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251776157885396 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251771345773901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251766570860183 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251761832856703 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251757131478144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251752466441394 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251747837465530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251743244271798 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251738686583600 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251734164126480 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251729676628099 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251725223818227 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251720805428719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251716421193505 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251712070848573 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251707754131946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251703470783678 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251699220545830 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251695003162458 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251690818379596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251686665945242 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251682545609340 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251678457123767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251674400242320 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251670374720697 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251666380316486 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251662416789149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251658483900007 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251654581412226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251650709090801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251646866702546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251643054016076 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251639270801796 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251635516831885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251631791880282 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251628095722676 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251624428136488 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251620788900860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251617177796640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251613594606374 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251610039114283 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251606511106262 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251603010369856 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251599536694256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251596089870281 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251592669690368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251589275948554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251585908440475 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251582566963343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251579251315936 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251575961298591 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251572696713187 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251569457363134 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251566243053361 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251563053590307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251559888781905 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251556748437574 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251553632368207 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251550540386157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251547472305228 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251544427940664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251541407109136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251538409628734 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251535435318952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251532484000681 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251529555496195 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251526649629144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251523766224540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251520905108745 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251518066109470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251515249055749 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251512453777945 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251509680107730 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251506927878074 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251504196923243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251501487078781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251498798181504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251496130069490 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251493482582068 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251490855559810 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251488248844519 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251485662279221 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251483095708156 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251480548976770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251478021931699 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251475514420767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251473026292977 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251470557398495 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251468107588647 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251465676715908 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251463264633895 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251460871197353 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251458496262153 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251456139685279 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251453801324820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251451481039963 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251449178690984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251446894139237 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251444627247148 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251442377878209 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251440145896964 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251437931169007 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251435733560967 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251433552940509 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251431389176318 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251429242138094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251427111696545 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251424997723378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251422900091292 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251420818673970 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251418753346072 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251416703983224 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251414670462017 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251412652659996 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251410650455649 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251408663728406 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251406692358630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251404736227605 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251402795217537 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251400869211539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251398958093630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251397061748723 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251395180062626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251393312922021 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251391460214475 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251389621828416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251387797653143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251385987578802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251384191496396 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251382409297764 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251380640875585 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251378886123367 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251377144935440 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251375417206952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251373702833862 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251372001712930 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251370313741719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251368638818580 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251366976842650 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251365327713848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251363691332866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251362067601161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251360456420955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251358857695223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251357271327694 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251355697222837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251354135285861 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251352585422709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251351047540048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251349521545271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251348007346482 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251346504852499 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251345013972843 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251343534617736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251342066698091 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251340610125512 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251339164812286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251337730671379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251336307616426 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251334895561735 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251333494422272 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251332104113663 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251330724552185 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251329355654759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251327997338957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251326649522979 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251325312125663 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251323985066471 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251322668265490 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251321361643422 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251320065121586 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251318778621904 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251317502066908 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251316235379722 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251314978484070 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251313731304262 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251312493765193 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251311265792343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251310047311762 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251308838250074 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251307638534473 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251306448092713 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251305266853105 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251304094744518 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251302931696368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251301777638618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251300632501773 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251299496216871 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251298368715489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251297249929729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251296139792219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251295038236108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251293945195061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251292860603256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251291784395383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251290716506629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251289656872691 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251288605429758 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251287562114512 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251286526864127 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251285499616260 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251284480309054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251283468881124 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251282465271566 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251281469419942 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251280481266282 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251279500751083 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251278527815298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251277562400338 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251276604448067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251275653900797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251274710701289 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251273774792744 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251272846118803 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251271924623540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251271010251466 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251270102947517 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251269202657058 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251268309325873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251267422900166 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251266543326558 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251265670552085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251264804524185 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251263945190709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251263092499908 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251262246400435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251261406841339 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251260573772061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251259747142436 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251258926902684 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251258113003413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251257305395608 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251256504030639 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251255708860247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251254919836547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251254136912026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251253360039538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251252589172298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251251824263887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251251065268243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251250312139660 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251249564832785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251248823302616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251248087504500 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251247357394126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251246632927531 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251245914061084 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251245200751498 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251244492955819 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251243790631423 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251243093736018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251242402227637 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251241716064638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251241035205701 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251240359609825 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251239689236328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251239024044840 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251238363995302 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251237709047969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251237059163401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251236414302461 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251235774426317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251235139496436 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251234509474584 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251233884322821 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251233264003502 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251232648479271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251232037713062 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251231431668095 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251230830307877 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251230233596192 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251229641497106 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251229053974967 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251228470994393 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251227892520277 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251227318517785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251226748952350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251226183789675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251225622995726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251225066536732 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251224514379184 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251223966489832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251223422835682 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251222883383996 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251222348102290 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251221816958328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251221289920126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251220766955947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251220248034297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251219733123929 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251219222193835 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251218715213246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251218212151635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251217712978705 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251217217664398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251216726178887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251216238492575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251215754576094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251215274400303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251214797936286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251214325155352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251213856029030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251213390529068 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251212928627437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251212470296321 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251212015508118 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251211564235444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251211116451122 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251210672128187 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251210231239883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251209793759659 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251209359661172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251208928918280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251208501505045 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251208077395727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251207656564788 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251207238986886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251206824636876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251206413489804 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251206005520912 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251205600705632 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251205199019588 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251204800438590 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251204404938636 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251204012495910 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251203623086778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251203236687792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251202853275682 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251202472827361 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251202095319917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251201720730618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251201349036906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251200980216398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251200614246885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251200251106328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251199890772861 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251199533224782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251199178440560 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251198826398833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251198477078401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251198130458225 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251197786517435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251197445235318 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251197106591324 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251196770565058 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251196437136286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251196106284929 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251195777991064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251195452234922 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251195128996884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251194808257488 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251194489997417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251194174197506 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251193860838740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251193549902247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251193241369302 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251192935221328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251192631439887 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251192330006686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251192030903574 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251191734112539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251191439615708 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251191147395347 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251190857433859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251190569713782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251190284217792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251190000928694 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251189719829430 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251189440903073 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251189164132825 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251188889502021 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251188616994120 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251188346592716 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251188078281522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251187812044384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251187547865266 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251187285728262 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251187025617585 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251186767517573 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251186511412681 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251186257287489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251186005126693 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251185754915107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251185506637666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251185260279417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251185015825525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251184773261270 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251184532572045 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251184293743355 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251184056760818 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251183821610164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251183588277232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251183356747971 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251183127008440 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182899044802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182672843330 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182448390403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182225672504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251182004676222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251181785388249 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251181567795378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251181351884508 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251181137642635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180925056859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180714114378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180504802489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180297108587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251180091020167 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179886524816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179683610222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179482264163 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179282474516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251179084229250 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178887516426 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178692324199 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178498640813 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178306454606 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251178115754006 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177926527527 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177738763775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177552451441 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177367579309 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177184136245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251177002111201 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176821493217 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176642271415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176464435005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176287973275 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251176112875600 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175939131435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175766730319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175595661868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175425915783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175257481841 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251175090349898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174924509890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174759951832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174596665811 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174434641998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174273870634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251174114342037 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173956046602 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173798974795 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173643117159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173488464307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173335006927 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173182735777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251173031641689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172881715562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172732948370 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172585331152 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172438855020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172293511154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172149290800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251172006185275 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171864185959 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171723284303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171583471821 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171444740096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171307080769 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171170485554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251171034946225 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170900454619 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170767002638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170634582244 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170503185464 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170372804386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170243431158 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251170115057989 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169987677149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169861280967 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169735861831 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169611412189 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169487924547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169365391469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169243805575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169123159544 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251169003446111 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168884658067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168766788257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168649829586 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168533775008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168418617537 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168304350236 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168190966225 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251168078458677 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167966820816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167856045918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167746127314 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167637058385 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167528832561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167421443327 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167314884216 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167209148809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167104230740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251167000123692 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166896821395 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166794317627 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166692606217 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166591681041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166491536018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166392165120 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166293562362 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166195721807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166098637562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251166002303781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165906714664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165811864453 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165717747439 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165624357951 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165531690368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165439739107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165348498634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165257963451 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165168128108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251165078987196 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164990535346 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164902767232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164815677567 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164729261109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164643512653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164558427035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164473999132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164390223859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164307096172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164224611064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164142763569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251164061548758 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163980961740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163900997662 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163821651709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163742919103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163664795102 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163587275003 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163510354136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163434027870 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163358291609 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163283140791 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163208570892 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163134577421 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251163061155921 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162988301972 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162916011186 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162844279210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162773101725 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162702474444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162632393115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162562853516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162493851460 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162425382794 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162357443391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162290029162 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162223136048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162156760019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162090897080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251162025543263 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161960694633 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161896347285 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161832497344 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161769140966 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161706274334 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161643893664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161581995197 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161520575209 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161459629998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161399155896 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161339149261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161279606479 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161220523965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161161898161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161103725534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251161046002585 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160988725837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160931891840 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160875497171 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160819538434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160764012261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160708915307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160654244254 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160599995809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160546166707 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160492753706 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160439753589 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160387163165 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160334979266 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160283198751 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160231818500 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160180835422 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160130246442 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160080048519 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251160030238626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159980813766 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159931770961 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159883107259 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159834819729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159786905462 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159739361575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159692185204 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159645373507 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159598923666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159552832884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159507098386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159461717417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159416687243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159372005155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159327668461 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159283674491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159240020595 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159196704145 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159153722534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159111073170 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159068753489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251159026760939 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158985092994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158943747143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158902720898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158862011785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158821617356 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158781535177 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158741762835 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158702297934 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158663138098 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158624280969 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158585724206 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158547465490 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158509502514 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158471832992 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158434454658 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158397365259 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158360562562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158324044352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158287808429 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158251852610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158216174731 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158180772643 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158145644215 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158110787330 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158076199890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158041879812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251158007825030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157974033491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157940503164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157907232026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157874218075 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157841459323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157808953797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157776699540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157744694610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157712937078 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157681425034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157650156578 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157619129830 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157588342918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157557793990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157527481207 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157497402743 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157467556785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157437941538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157408555218 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157379396055 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157350462293 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157321752191 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157293264018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157264996059 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157236946614 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157209113991 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157181496515 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157154092523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157126900365 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157099918404 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157073145013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157046578582 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251157020217510 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156994060210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156968105107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156942350638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156916795252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156891437409 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156866275583 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156841308259 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156816533934 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156791951115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156767558322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156743354086 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156719336949 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156695505465 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156671858200 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156648393730 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156625110639 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156602007528 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156579083005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156556335689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156533764211 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156511367211 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156489143340 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156467091260 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156445209644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156423497174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156401952541 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156380574450 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156359361612 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156338312749 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156317426595 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156296701891 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156276137391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156255731855 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156235484054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156215392769 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156195456790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156175674917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156156045959 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156136568733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156117242067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156098064797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156079035767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156060153833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156041417856 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156022826709 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251156004379273 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155986074435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155967911094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155949888156 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155932004537 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155914259159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155896650954 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155879178859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155861841825 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155844638807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155827568768 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155810630682 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155793823527 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155777146293 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155760597973 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155744177573 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155727884103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155711716582 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155695674036 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155679755501 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155663960015 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155648286630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155632734400 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155617302389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155601989670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155586795317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155571718416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155556758061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155541913350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155527183389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155512567292 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155498064177 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155483673171 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155469393409 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155455224029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155441164180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155427213013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155413369689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155399633375 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155386003244 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155372478472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155359058248 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155345741763 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155332528216 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155319416809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155306406753 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155293497266 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155280687569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155267976892 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155255364469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155242849540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155230431352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155218109157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155205882213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155193749783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155181711138 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155169765552 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155157912306 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155146150685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155134479983 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155122899494 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155111408525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155100006380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155088692374 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155077465826 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155066326060 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155055272403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155044304192 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155033420767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155022621470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155011905652 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251155001272668 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154990721877 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154980252644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154969864338 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154959556335 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154949328013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154939178756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154929107952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154919114998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154909199288 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154899360227 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154889597223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154879909686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154870297035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154860758690 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154851294077 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154841902625 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154832583770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154823336949 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154814161607 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154805057191 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154796023152 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154787058946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154778164034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154769337880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154760579953 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154751889724 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154743266671 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154734710276 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154726220021 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154717795395 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154709435892 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154701141010 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154692910246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154684743106 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154676639099 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154668597736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154660618534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154652701010 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154644844689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154637049098 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154629313768 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154621638231 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154614022026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154606464696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154598965782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154591524837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154584141410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154576815057 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154569545337 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154562331812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154555174048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154548071615 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154541024082 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154534031027 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154527092029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154520206670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154513374536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154506595213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154499868295 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154493193376 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154486570053 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154479997930 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154473476610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154467005700 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154460584810 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154454213554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154447891547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154441618410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154435393765 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154429217237 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154423088452 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154417007043 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154410972645 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154404984893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154399043425 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154393147886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154387297919 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154381493172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154375733297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154370017946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154364346774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154358719441 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154353135608 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154347594937 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154342097097 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 1.251154336641754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154331228581 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154325857252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154320527444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154315238836 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154309991109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154304783947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154299617036 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154294490066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154289402727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154284354714 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154279345723 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154274375450 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154269443598 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154264549869 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154259693970 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154254875606 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154250094489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154245350329 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154240642842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154235971744 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154231336754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154226737593 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154222173983 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154217645650 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154213152321 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154208693727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154204269596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154199879664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154195523667 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154191201342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154186912429 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154182656669 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154178433806 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154174243586 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154170085756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154165960068 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154161866270 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154157804118 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154153773365 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154149773772 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154145805095 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154141867096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154137959538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154134082185 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154130234805 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154126417165 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154122629036 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154118870188 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154115140397 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154111439437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154107767085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154104123122 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154100507325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154096919480 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154093359369 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154089826776 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154086321492 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154082843303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154079392001 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154075967378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154072569226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154069197342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154065851524 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154062531569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154059237277 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154055968450 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154052724891 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154049506405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154046312799 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154043143878 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154039999454 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154036879335 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154033783337 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154030711269 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154027662950 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154024638193 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154021636818 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154018658644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154015703491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154012771182 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154009861540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154006974389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154004109556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251154001266868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153998446154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153995647245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153992869971 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153990114164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153987379662 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153984666297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153981973906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153979302328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153976651400 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153974020965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153971410863 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153968820937 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153966251031 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153963700991 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153961170663 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153958659893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153956168532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153953696431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153951243438 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153948809407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153946394191 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153943997646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153941619624 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153939259986 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153936918587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153934595288 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153932289947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153930002428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153927732590 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153925480299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153923245417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153921027812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153918827349 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153916643895 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153914477319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153912327492 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153910194282 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153908077563 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153905977205 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153903893083 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153901825072 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153899773047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153897736884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153895716460 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153893711654 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153891722345 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153889748414 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153887789742 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153885846210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153883917701 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153882004101 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153880105291 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153878221161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153876351594 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153874496479 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153872655705 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153870829161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153869016733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153867218318 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153865433803 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153863663084 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153861906052 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153860162602 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153858432629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153856716027 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153855012697 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153853322532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153851645433 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153849981298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153848330026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153846691520 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153845065678 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153843452405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153841851602 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153840263173 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153838687024 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153837123057 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153835571180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153834031299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153832503322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153830987155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153829482710 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153827989893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153826508616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153825038789 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153823580324 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153822133133 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153820697129 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153819272224 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153817858336 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153816455376 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153815063261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153813681907 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153812311231 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153810951151 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153809601583 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153808262448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153806933665 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153805615154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153804306833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153803008627 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153801720456 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153800442243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153799173909 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153797915380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153796666580 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153795427433 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153794197866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153792977801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153791767169 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153790565894 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153789373906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153788191132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153787017500 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153785852941 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153784697384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153783550759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153782412998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153781284032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153780163792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153779052212 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153777949226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153776854764 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153775768763 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153774691157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153773621881 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153772560870 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153771508061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153770463391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153769426795 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153768398213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153767377581 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153766364839 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153765359925 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153764362780 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153763373342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153762391554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153761417354 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153760450684 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153759491488 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153758539705 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153757595280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153756658155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153755728275 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153754805582 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153753890022 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153752981539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153752080080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153751185587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153750298010 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153749417293 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153748543385 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153747676232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153746815782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153745961984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153745114785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153744274135 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153743439984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153742612280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153741790974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153740976017 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153740167360 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153739364955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153738568751 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153737778702 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153736994760 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153736216879 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153735445010 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153734679107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153733919126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153733165019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153732416741 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153731674247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153730937492 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153730206434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153729481026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153728761226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153728046990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153727338274 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153726635037 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153725937236 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153725244829 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153724557775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153723876032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153723199558 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153722528313 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153721862257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153721201351 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153720545552 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153719894823 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153719249125 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153718608417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153717972662 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153717341822 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153716715858 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153716094733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153715478408 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153714866848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153714260016 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153713657875 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153713060388 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153712467520 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153711879234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153711295496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153710716270 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153710141522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153709571217 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153709005320 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153708443797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153707886616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153707333740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153706785139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153706240778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153705700626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153705164649 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153704632815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153704105092 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153703581449 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153703061852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153702546273 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153702034679 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153701527039 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153701023324 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153700523503 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153700027546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153699535422 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153699047101 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153698562556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153698081756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153697604674 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153697131278 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153696661542 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153696195437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153695732936 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153695274009 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153694818630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153694366771 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153693918404 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153693473505 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153693032044 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153692593995 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153692159332 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153691728030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153691300061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153690875401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153690454023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153690035903 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153689621015 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153689209333 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153688800835 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153688395493 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153687993285 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153687594186 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153687198172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153686805220 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153686415305 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153686028403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153685644493 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153685263550 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153684885554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153684510477 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153684138300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153683769001 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153683402556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153683038943 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153682678142 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153682320129 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153681964884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153681612385 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153681262610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153680915540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153680571153 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153680229427 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153679890343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153679553880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153679220018 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153678888737 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153678560017 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153678233837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153677910179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153677589023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153677270350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153676954139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153676640373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153676329033 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153676020099 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153675713554 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153675409377 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153675107552 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153674808061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153674510884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153674216005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153673923404 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153673633066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153673344972 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153673059105 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153672775448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153672493984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153672214695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153671937565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153671662577 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153671389716 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153671118962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153670850302 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153670583720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153670319198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153670056720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153669796271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153669537836 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153669281398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153669026944 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153668774455 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153668523918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153668275317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153668028639 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153667783868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153667540988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153667299987 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153667060848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153666823557 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153666588101 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153666354466 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153666122635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153665892597 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153665664337 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153665437842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153665213098 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664990090 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664768807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664549234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664331359 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153664115166 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663900646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663687785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663476568 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663266985 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153663059020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662852664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662647903 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662444725 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662243117 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153662043068 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661844565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661647597 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661452151 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661258215 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153661065780 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660874832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660685359 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660497352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660310797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153660125685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659942003 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659759741 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659578889 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659399434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659221367 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153659044677 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658869351 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658695381 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658522756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658351465 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658181499 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153658012846 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657845496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657679441 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657514669 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657351171 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657188937 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153657027957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656868221 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656709719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656552444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656396384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656241530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153656087873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655935405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655784114 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655633993 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655485032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655337223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655190557 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153655045025 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654900617 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654757325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654615141 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654474057 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654334062 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654195151 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153654057312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653920540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653784824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653650158 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653516532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653383940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653252372 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153653121822 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652992280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652863741 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652736194 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652609634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652484052 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652359440 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652235793 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153652113100 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651991356 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651870553 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651750684 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651631743 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651513719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651396609 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651280403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651165096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153651050680 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650937149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650824495 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650712712 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650601794 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650491732 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650382522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650274155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650166626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153650059929 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649954056 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649849002 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649744759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649641323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649538686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649436843 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649335786 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649235511 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649136011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153649037280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648939312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648842102 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648745643 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648649930 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648554956 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648460718 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648367206 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648274418 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648182347 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648090988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153648000336 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647910383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647821126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647732560 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647644678 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647557475 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647470946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647385087 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647299891 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647215352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647131469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153647048233 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646965640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646883687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646802366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646721675 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646641606 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646562158 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646483323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646405097 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646327477 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646250455 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646174030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646098196 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153646022947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645948281 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645874191 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645800674 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645727726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645655341 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645583515 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645512246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645441527 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645371354 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645301724 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645232632 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645164075 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645096047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153645028546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644961565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644895103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644829154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644763715 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644698783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644634351 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644570419 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644506980 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644444032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644381570 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644319591 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644258092 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644197067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644136515 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644076430 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153644016810 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643957650 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643898948 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643840700 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643782902 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643725551 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643668643 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643612175 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643556144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643500546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643445377 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643390635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643336316 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643282417 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643228935 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643175866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643123206 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643070955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153643019107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642967660 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642916611 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642865956 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642815693 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642765819 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642716329 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642667223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642618496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642570146 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642522169 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642474564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642427326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642380453 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642333943 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642287792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642241999 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642196559 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642151471 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642106730 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642062335 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153642018284 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641974574 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641931202 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641888164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641845459 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641803085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641761037 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641719315 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641677915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641636836 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641596074 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641555627 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641515493 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641475669 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641436153 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641396941 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641358034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641319427 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641281119 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641243107 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641205388 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641167961 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641130824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641093973 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641057407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153641021125 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640985122 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640949398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640913950 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640878776 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640843873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640809241 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640774876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640740777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640706942 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640673368 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640640053 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640606997 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640574196 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640541647 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640509352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640477305 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640445507 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640413953 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640382644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640351577 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640320750 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640290162 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640259809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640229691 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640199807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640170153 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640140729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640111532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640082561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640053813 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153640025289 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639996983 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639968898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639941029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639913376 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639885936 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639858708 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639831691 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639804883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639778282 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639751886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639725695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639699707 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639673919 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639648330 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639622940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639597745 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639572745 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639547939 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639523323 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639498900 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639474664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639450615 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639426753 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639403075 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639379580 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639356267 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639333133 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639310179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639287403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639264801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639242375 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639220123 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639198042 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639176132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639154391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639132819 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639111413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639090172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639069096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639048183 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639027431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153639006840 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638986408 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638966134 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638946016 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638926055 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638906247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638886592 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638867090 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638847738 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638828536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638809482 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638790575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638771815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638753200 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638734728 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638716400 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638698213 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638680167 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638662260 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638644491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638626860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638609365 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638592006 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638574781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638557689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638540728 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638523899 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638507200 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638490630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638474189 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638457875 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638441686 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638425622 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638409684 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638393867 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638378174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638362601 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638347149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638331816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638316603 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638301506 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638286525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638271662 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638256913 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638242277 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638227755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638213346 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638199047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638184860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638170782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638156812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638142952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638129197 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638115549 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638102007 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638088569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638075236 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638062005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638048876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638035849 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638022923 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153638010096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637997370 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637984741 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637972210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637959775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637947437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637935195 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637923046 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637910991 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637899031 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637887161 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637875386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637863699 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637852104 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637840598 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637829181 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637817852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637806611 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637795457 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637784388 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637773406 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637762509 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637751695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637740965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637730319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637719754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637709272 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637698870 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637688548 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637678307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637668144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637658061 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637648054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637638126 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637628274 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637618498 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637608798 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637599173 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637589622 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637580145 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637570742 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637561411 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637552152 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637542964 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637533848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637524803 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637515827 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637506920 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637498083 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637489313 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637480612 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637471978 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637463410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637454909 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637446473 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637438103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637429798 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637421556 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637413378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637405264 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637397212 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637389222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637381295 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637373428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637365622 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637357876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637350192 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637342565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637334998 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637327489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637320038 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637312646 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637305309 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637298030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637290807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637283641 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637276529 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637269472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637262470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637255522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637248628 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637241787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637234999 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637228263 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637221579 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637214947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637208366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637201837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637195358 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637188929 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637182548 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637176219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637169938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637163705 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637157520 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637151383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637145294 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637139252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637133257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637127307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637121403 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637115547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637109734 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637103966 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637098244 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637092565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637086931 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637081339 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637075792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637070286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637064824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637059405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637054026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637048689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637043394 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637038139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637032925 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637027752 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637022618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637017524 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637012469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637007454 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153637002478 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636997539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636992638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636987777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636982952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636978165 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636973415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636968701 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636964023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636959383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636954778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636950208 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636945674 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636941175 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636936710 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636932280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636927885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636923523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636919195 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636914901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636910639 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636906411 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636902215 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636898052 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636893921 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636889821 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636885754 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636881718 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636877713 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636873740 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636869797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636865884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636862002 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636858149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636854326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636850534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636846770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636843035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636839329 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636835652 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636832004 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636828383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636824790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636821226 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636817688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636814179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636810696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636807240 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636803811 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636800409 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636797033 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636793682 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636790358 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636787059 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636783787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636780539 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636777316 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636774119 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636770945 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636767796 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636764673 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636761572 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636758496 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636755444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636752415 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636749410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636746428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636743469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636740533 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636737620 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636734729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636731860 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636729014 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636726189 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636723386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636720606 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636717847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636715109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636712391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636709696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636707021 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636704367 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636701732 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636699119 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636696525 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636693952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636691399 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636688866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636686352 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636683857 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636681381 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636678925 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636676489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636674070 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636671670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636669289 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636666927 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636664581 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636662256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636659947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636657656 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636655384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636653129 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636650890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636648670 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636646467 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636644280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636642111 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636639959 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636637823 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636635703 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636633600 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636631514 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636629443 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636627388 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636625350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636623326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636621319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636619326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636617350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636615389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636613443 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636611512 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636609596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636607695 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636605808 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636603936 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636602078 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636600235 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636598407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636596591 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636594792 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636593004 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636591231 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636589472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636587726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636585994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636584275 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636582570 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636580878 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636579198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636577532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636575879 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636574238 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636572610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636570994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636569391 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636567801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636566223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636564657 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636563103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636561561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636560031 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636558513 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636557006 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636555511 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636554028 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636552557 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636551096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636549647 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636548209 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636546783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636545366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636543962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636542569 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636541185 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636539813 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636538451 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636537099 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636535759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636534428 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636533108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636531797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636530498 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636529208 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636527928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636526658 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636525398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636524148 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636522907 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636521676 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636520454 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636519242 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636518039 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636516845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636515661 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636514486 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636513319 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636512162 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636511015 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636509876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636508745 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636507624 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636506510 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636505406 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636504310 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636503223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636502144 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636501073 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636500011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636498956 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636497911 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636496873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636495842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636494820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636493807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636492800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636491802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636490811 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636489829 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636488852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636487885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636486924 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636485971 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636485025 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636484087 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636483156 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636482232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636481315 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636480406 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636479504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636478608 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636477719 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636476837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636475962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636475094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636474232 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636473378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636472528 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636471687 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636470852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636470023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636469201 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636468385 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636467575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636466771 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636465975 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636465183 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636464398 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636463619 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636462847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636462080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636461318 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636460564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636459814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636459071 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636458333 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636457601 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636456875 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636456154 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636455439 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636454729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636454025 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636453326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636452633 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636451946 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636451263 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636450585 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636449913 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636449246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636448584 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636447927 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636447276 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636446629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636445988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636445351 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636444720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636444093 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636443471 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636442854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636442242 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636441634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636441031 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636440433 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636439839 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636439250 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636438666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636438085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636437511 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636436939 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636436373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636435810 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636435252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636434699 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636434149 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636433604 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636433064 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636432527 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636431994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636431466 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636430941 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636430421 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636429905 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636429393 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636428884 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636428380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636427880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636427383 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636426890 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636426401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636425917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636425435 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636424957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636424483 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636424013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636423546 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636423083 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636422623 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636422167 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636421715 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636421266 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636420821 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636420378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636419940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636419504 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636419073 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636418644 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636418219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636417797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636417379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636416962 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636416551 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636416142 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636415736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636415334 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636414934 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636414537 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636414143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636413753 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636413366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636412981 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636412599 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636412221 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636411846 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636411472 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636411104 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636410736 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636410372 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636410011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636409653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636409297 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636408944 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636408593 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636408247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636407901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636407559 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636407219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636406883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636406549 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636406217 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636405888 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636405561 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636405237 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636404915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636404596 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636404280 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636403965 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636403654 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636403344 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636403038 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636402733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636402431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636402131 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636401833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636401538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636401245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636400955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636400666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636400379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636400095 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636399814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636399534 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636399256 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636398981 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636398707 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636398437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636398168 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636397901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636397637 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636397373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636397113 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636396854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636396597 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636396342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636396089 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636395838 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636395590 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636395342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636395097 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636394854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636394613 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636394373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636394135 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636393900 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636393666 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636393434 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636393204 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392976 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392748 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636392078 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636391859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636391641 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636391424 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636391209 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390996 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390784 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390575 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636390160 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389752 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389549 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389349 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636389150 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388953 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388758 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388563 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388370 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636388179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387990 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387614 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387429 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636387063 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386882 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386702 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386524 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386348 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636386171 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385997 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385482 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385313 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636385146 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384980 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384815 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384651 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384327 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384168 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636384009 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383851 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383540 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383386 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636383082 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382635 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382488 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382197 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636382054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381912 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381771 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381630 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381491 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381353 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381216 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636381080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380945 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380679 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380416 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380287 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380158 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636380030 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379903 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379653 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379529 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379285 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636379043 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378924 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378806 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378689 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378572 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378457 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378342 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378229 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378116 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636378004 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377674 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377457 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636377035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376829 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376626 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376524 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376425 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376326 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376228 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636376034 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375939 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375843 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375750 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375656 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375563 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375470 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375379 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375288 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636375020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374932 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374672 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374502 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374418 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 1.251153636374335 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374170 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374089 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636374008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373848 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373769 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373691 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373614 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373459 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373308 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636373013 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372869 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372726 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372656 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372586 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372380 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372245 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372179 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372113 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636372047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371982 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371665 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371603 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371541 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371481 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371420 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371360 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371240 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371182 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371124 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371065 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636371008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370951 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370895 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370838 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370782 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370672 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370618 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370510 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370458 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370405 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370353 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370249 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370147 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370096 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636370047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369997 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369948 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369900 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369851 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369803 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369708 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369660 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369615 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369568 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369522 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369477 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369432 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369387 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369343 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369299 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369254 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369211 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369168 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369125 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369082 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636369041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368999 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368958 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368917 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368835 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368795 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368715 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368677 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368637 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368598 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368560 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368484 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368447 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368410 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368373 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368336 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368300 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368264 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368228 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368192 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368157 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368123 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368088 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636368019 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367985 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367919 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367756 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367723 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367693 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367661 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367629 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367599 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367568 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367538 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367507 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367478 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367448 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367418 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367359 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367331 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367303 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367274 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367246 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367218 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367190 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367164 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367109 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367082 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367055 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636367002 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366977 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366951 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366926 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366900 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366874 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366850 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366825 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366751 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366727 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366704 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366680 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366657 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366634 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366610 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366564 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366541 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366519 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366497 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366475 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366453 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366409 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366387 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366367 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366345 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366325 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366304 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366283 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366262 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366243 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366202 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366182 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366163 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366124 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366105 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366085 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366066 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366028 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636366011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365992 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365956 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365920 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365902 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365867 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365850 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365749 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365733 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365717 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365701 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365685 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365669 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365654 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365638 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365623 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365607 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365592 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365577 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365562 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365547 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365532 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365518 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365503 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365474 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365460 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365446 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365432 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365418 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365404 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365390 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365377 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365363 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365350 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365337 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365324 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365311 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365298 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365285 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365272 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365260 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365248 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365234 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365222 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365198 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365186 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365174 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365162 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365150 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365127 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365115 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365103 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365092 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365081 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365070 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365059 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365048 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365037 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365026 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365015 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636365005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364984 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364974 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364963 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364953 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364942 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364933 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364923 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364913 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364903 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364864 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364836 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364827 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364818 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364808 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364772 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364764 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364755 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364746 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364738 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364729 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364720 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364713 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364704 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364696 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364688 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364680 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364671 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364664 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364655 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364647 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364640 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364631 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364624 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364616 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364609 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364602 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364594 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364587 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364579 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364572 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364565 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364558 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364551 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364543 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364536 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364530 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364523 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364516 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364508 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364502 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364495 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364489 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364482 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364476 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364469 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364462 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364456 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364450 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364444 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364437 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364431 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364426 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364420 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364413 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364407 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364401 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364396 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364389 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364384 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364378 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364372 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364366 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364360 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364355 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364349 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364344 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364339 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364333 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364328 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364322 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364317 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364312 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364307 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364302 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364296 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364291 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364286 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364281 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364276 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364271 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364267 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364261 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364257 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364252 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364247 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364242 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364237 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364233 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364228 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364223 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364219 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364214 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364210 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364206 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364202 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364197 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364193 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364188 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364184 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364180 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364175 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364172 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364167 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364163 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364159 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364155 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364151 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364147 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364143 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364139 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364136 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364132 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364128 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364123 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364120 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364116 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364112 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364108 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364106 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364101 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364098 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364094 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364091 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364088 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364084 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364080 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364077 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364074 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364071 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364067 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364063 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364060 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364057 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364054 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364051 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364047 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364044 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364041 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364038 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364035 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364032 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364029 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364025 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364023 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364020 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364017 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364014 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364011 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364008 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364005 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636364003 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363999 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363996 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363994 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363992 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363988 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363986 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363983 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363980 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363978 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363975 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363973 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363970 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363967 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363964 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363963 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363959 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363957 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363955 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363952 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363950 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363947 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363945 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363942 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363940 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363938 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363935 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363933 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363931 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363928 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363927 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363924 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363922 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363919 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363918 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363915 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363913 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363911 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363909 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363906 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363904 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363902 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363901 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363898 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363896 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363894 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363893 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363891 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363888 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363886 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363885 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363883 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363880 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363879 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363877 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363876 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363873 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363871 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363869 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363868 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363866 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363864 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363862 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363861 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363859 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363857 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363856 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363854 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363852 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363850 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363849 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363847 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363845 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363844 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363842 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363841 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363839 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363838 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363837 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363834 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363833 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363832 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363830 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363828 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363827 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363826 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363824 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363822 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363822 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363820 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363818 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363817 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363816 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363814 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363813 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363812 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363809 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363807 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363805 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363804 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363802 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363801 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363800 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363799 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363797 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363796 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363795 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363794 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363793 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363791 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363790 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363789 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363787 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363785 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363784 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363783 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363781 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363779 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363778 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363777 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363775 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363774 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363773 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363772 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363771 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363770 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363769 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363767 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363766 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363766 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363765 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363764 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363763 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363762 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363761 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363759 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n",
      "error: 1.251153636363757 | alpha: 0.000823913667101 | learning rate: 1.000000000000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b9e82b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from notes_utilities import pnorm_ball_line\n",
    "from IPython import display\n",
    "\n",
    "# initialize data\n",
    "x = np.array([10., 8., 13., 9., 11., 14., 6., 4., 12., 7., 5.])\n",
    "y = np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
    "N = len(x)\n",
    "\n",
    "# create the design matrix\n",
    "A = np.vstack((np.ones(N), x)).T\n",
    "\n",
    "# calculate values using numpy (np) \n",
    "w_best, E, rank, s = np.linalg.lstsq(A, y)\n",
    "print(\"best w (numpy result):\", w_best)\n",
    "\n",
    "# calculate the min value using w_best\n",
    "err = y-A.dot(w_best) \n",
    "E_min = np.sum(err**2) / N\n",
    "print(\"min error (numpy result):\", E_min, \"\\n\")\n",
    "\n",
    "def draw_pnorm():\n",
    "    for i in range(0, 10):\n",
    "        ln = pnorm_ball_line(mu=w_best, A = i*4*np.linalg.cholesky(np.linalg.inv(A.T.dot(A))),linewidth=1)\n",
    "        plt.gca().add_line(ln) \n",
    "\n",
    "\n",
    "\n",
    "def inspect_momentum():\n",
    "    alpha = 0.001\n",
    "    beta = 0.95\n",
    "    learning_rate = 1.1\n",
    "    \n",
    "    # set start position for w\n",
    "    w0 = np.array([2., 1.])\n",
    "    w = w0.copy()\n",
    "    p = 0\n",
    "   \n",
    "    # set bounds and draw title\n",
    "    # plt.title('alpha = '+ str(alpha) + ' beta = ' +str(beta))\n",
    "    plt.xlim((1.8,4.3))\n",
    "    plt.ylim((0,1.2))\n",
    "    \n",
    "    # draw start position\n",
    "    plt.plot(w[0],w[1],'ko')\n",
    "    \n",
    "    # draw best position\n",
    "    plt.plot(w_best[0],w_best[1],'ro')\n",
    "    \n",
    "    E_n = 10000\n",
    "    EPOCHS = 100000\n",
    "    # create a 2 * EPOCHS array\n",
    "    W = np.zeros((2,EPOCHS))\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        # Error\n",
    "        err = y-A.dot(w)\n",
    "        W[:,i] = w\n",
    "        \n",
    "        # Mean square error\n",
    "        E = np.sum(err**2) / N\n",
    "        \n",
    "        if E > E_n:\n",
    "            alpha = alpha / learning_rate\n",
    "            learning_rate = 1 + (learning_rate - 1) / 2\n",
    "        elif E_n == E:\n",
    "            break\n",
    "        else:\n",
    "            E_n = E\n",
    "            print(\"error: %8.15f | alpha: %8.15f | learning rate: %8.15f\" % (E, alpha, learning_rate))\n",
    "\n",
    "        # Gradient\n",
    "        dE = -2. * A.T.dot(err) / N\n",
    "        p = dE + beta * p\n",
    " \n",
    "        # Perfom one descent step\n",
    "        w = w - alpha * p \n",
    "        i= i +1\n",
    "    return W\n",
    "\n",
    "# run solution\n",
    "draw_pnorm()\n",
    "\n",
    "W = inspect_momentum()\n",
    "\n",
    "# draw solution\n",
    "plt.plot(W[0,:],W[1,:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
